{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0797178-d66a-40b8-9463-52e5c9a9a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038d1789-c58d-4b3d-afcb-269c6e40e3af",
   "metadata": {},
   "source": [
    "### Assitant Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb7a5867-4b2c-4b2b-9ef0-b6e1b75d6b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract distinct drugs and Y [SE/Diesease/CellLine]\n",
    "def distinct(data, drug1, drug2, Y): \n",
    "    distinct_drugs = set(data[drug1]).union(set(data[drug2])) \n",
    "    distinct_Y = set(data[Y])  \n",
    "    return(distinct_drugs, distinct_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b976c398-0dcf-4cee-9463-f1a3dfc6499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Index for drug, Y [SE/Diesease/CellLine]\n",
    "def drug_index(distinct_Drug):\n",
    "    drug = pd.DataFrame(distinct_Drug, columns = ['Drug_ID'])\n",
    "    drug[\"Drug_Index\"] = drug.index\n",
    "    return(drug) \n",
    "\n",
    "def y_index(distinct_Y, y_name):  \n",
    "    Y = pd.DataFrame(distinct_Y, columns=[y_name])\n",
    "    Y[y_name+\"_Index\"] = Y.index\n",
    "    return(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46a5fa3c-8ae1-4e7c-b1c0-5acb2da6a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D tensor built (Yabc) \n",
    "def labels_to_tensor(labels_triplets, Drug, Y):\n",
    "    labels_tensor = np.zeros((len(Drug), len(Drug), len(Y)))\n",
    "\n",
    "    # Classification(binary) problem\n",
    "    labels_tensor[labels_triplets[:,0], labels_triplets[:,1], labels_triplets[:,2]] = 1 \n",
    "    labels_tensor[labels_triplets[:,1], labels_triplets[:,0], labels_triplets[:,2]] = 1 \n",
    "    \n",
    "    return(labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50d2d402-4d28-4635-8098-a033473a7542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D tensor built (Yabc) \n",
    "def triplets_to_tensor(labels_triplets, Drug_num , Y_num):\n",
    "    \"\"\"\n",
    "    labels_triplets = [[ Drug1, Drug2, Y], [ ] [ ] ,,, [ ]]\n",
    "    Drug_num = distinct number of Drug\n",
    "    Y_num = distinct number of Y \n",
    "    \"\"\"\n",
    "    labels_tensor = np.zeros((Drug_num, Drug_num, Y_num))\n",
    "\n",
    "    labels_tensor[labels_triplets[:,0], labels_triplets[:,1], labels_triplets[:,2]] = 1 \n",
    "    labels_tensor[labels_triplets[:,1], labels_triplets[:,0], labels_triplets[:,2]] = 1 \n",
    "    return(labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb2e6956-27a0-47f3-a99c-7f9c03b901d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(array, name):\n",
    "    np.savetxt(\"../Final_DF/{}\".format(name), array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "548dd680-3da2-468c-9c32-bb6c372fd537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_smile(smiles):\n",
    "    # fingerprint\n",
    "    charset = set(\"\".join(list(smiles)))\n",
    "    char_to_int = dict((c,i) for i,c in enumerate(charset)) \n",
    "    int_to_char = dict((i,c) for i,c in enumerate(charset)) \n",
    "    embed = max([len(smile) for smile in smiles]) + 1\n",
    "    \n",
    "    ## one hot coding\n",
    "    one_hot =  np.zeros((smiles.shape[0], embed , len(charset)),dtype=np.int8)\n",
    "    for i, smile in enumerate(smiles):\n",
    "        for j, c in enumerate(smile):\n",
    "            one_hot[i,j+1,char_to_int[c]] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "158288a5-655f-45ea-9563-6fcfc02b323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_smile(data_indexed, drug_idx, columns):\n",
    "    \"\"\"\n",
    "    Merge Smile string into the drug_idx \n",
    "    \"\"\"\n",
    "    data_drug1_indexed = data_indexed[columns[0]].drop_duplicates().sort_values(columns[0][0])\n",
    "    data_drug2_indexed  = data_indexed[columns[1]].drop_duplicates().sort_values(columns[1][0])\n",
    "\n",
    "    # fillna(0) as each drug set do not contain all the distinct drugs \n",
    "    Drug1 = drug_idx.merge(data_drug1_indexed, left_on = \"Drug_Index\", right_on = columns[0][0], how='outer').fillna(0)\n",
    "    Drug_all = Drug1.merge(data_drug2_indexed, left_on = \"Drug_Index\", right_on = columns[1][0], how='outer').fillna(0)\n",
    "    \n",
    "    # merge them into one \n",
    "    case1 = Drug_all[Drug_all[columns[1][1]]==0].index\n",
    "    case2 = Drug1[Drug1[columns[0][1]]==0].index\n",
    "    for i in case1:\n",
    "        Drug_all.at[i,columns[1][1]]= Drug_all.at[i,columns[0][1]]\n",
    "    for i in case2: \n",
    "        Drug_all.at[i,columns[0][1]] = Drug_all.at[i,columns[1][1]]\n",
    "        \n",
    "    return(Drug_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed97d2cc-58de-42f3-bcea-487a44fe441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drug_combi_index(drug_idx):\n",
    "    \n",
    "    # all possible drug combination \n",
    "    drug_combi = list(itertools.combinations(drug_idx[\"Drug_Index\"], 2))\n",
    "    \n",
    "    # index for drug combination\n",
    "    combi_idx = pd.DataFrame(drug_combi,  columns =[\"Drug1_Index\", \"Drug2_Index\"])\n",
    "    combi_idx[\"Combi_Index\"] = combi_idx.index \n",
    "    \n",
    "    return(combi_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2331ff2-34cb-4b73-ba7e-5e474afde91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_indexed_combi(data_indexed, combi_idx):\n",
    "\n",
    "    # consider the oppositie orders too \n",
    "    combi_df = combi_idx\n",
    "    combi_df2 = combi_df.rename(columns = {\"Drug1_Index\" : \"Drug2_Index\", \"Drug2_Index\" : \"Drug1_Index\", \"Combi_Index\":\"Combi_Index2\"})\n",
    "    combi_df2 = combi_df2[[\"Drug1_Index\", \"Drug2_Index\",\"Combi_Index2\"]]\n",
    "    \n",
    "    # merge data_indexed with drug combination index\n",
    "    data_indexed_combi = data_indexed.merge(combi_df, how= 'left').merge(combi_df2, how = 'left')\n",
    "    data_indexed_combi[\"Combi_Index3\"] = data_indexed_combi.Combi_Index.fillna(0).astype(int) + data_indexed_combi.Combi_Index2.fillna(0).astype(int)    \n",
    "    data_indexed_combi = data_indexed_combi.drop(columns={\"Combi_Index\",\"Combi_Index2\"}).rename(columns={\"Combi_Index3\":\"Combi_Index\"})\n",
    "    return(data_indexed_combi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea19d65a-e601-40bc-95fd-13a2b2118092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_drugcombi(labels_triplets_drugcombi, combi_idx, Y_idx):\n",
    "    \"\"\"\n",
    "    Vectorizing Y using drug-drug-pair existence as side information\n",
    "    \n",
    "    Input: [data with indexed, drug combination indexed, Y_idx, Y_name]\n",
    "    Output: 2D tensor shaped as [Y, Drug_combination]\n",
    "    \"\"\"\n",
    "    # first column = Y_idx, second column = DrugCombi_idx\n",
    "    Y_drugcombi_idx = labels_triplets_drugcombi[:,2:4]\n",
    "\n",
    "    # vectorize into tensor as shaped of [Y, drugcombi]\n",
    "    Y_vectorized_drugcombi = np.zeros((len(Y_idx), len(combi_idx)))\n",
    "    Y_vectorized_drugcombi[Y_drugcombi_idx[:,0], Y_drugcombi_idx[:,1]] = 1 \n",
    "    return(Y_vectorized_drugcombi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1618f720-88e9-4a72-ae0a-f4b065d2a289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanimoto_similarity(drug1, drug2):\n",
    "    \n",
    "    both, onlyA ,onlyB = 0, 0, 0\n",
    "    \n",
    "    # for diagnoal \n",
    "    if np.array_equal(drug1, drug2):\n",
    "        return 1 \n",
    "    \n",
    "    for i in range(len(drug1)):\n",
    "        if drug1[i] == 1 and drug2[i] == 1:\n",
    "            both +=1\n",
    "        elif drug1[i] == 1 and drug2[i] == 0:\n",
    "            onlyA +=1\n",
    "        elif drug1[i] == 0 and drug2[i] == 1:\n",
    "            onlyB +=1 \n",
    "            \n",
    "    return(both/(onlyA +onlyB + both))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d4609a3-7ed6-4bc1-904d-28655ea0585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanimoto_similarity_matrix(drug_vectorized):\n",
    "    \n",
    "    similarity = np.zeros((drug_vectorized.shape[0], drug_vectorized.shape[0]))\n",
    "    for i, drug1 in enumerate(drug_vectorized):\n",
    "        for j, drug2 in enumerate(drug_vectorized):\n",
    "            similarity[i,j] = tanimoto_similarity(drug1, drug2)\n",
    "\n",
    "    return(similarity) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
